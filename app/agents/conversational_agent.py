# ruta: app/agents/conversational_agent.py

# (NUEVO) Importar AIMessage
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage
from langchain_openai import ChatOpenAI
from app.agents.rag_service import RAGService


class ConversationalAgent:

    def __init__(self):
        print("[ConversationalAgent] Inicializando...")

        self.llm = ChatOpenAI(
            model="gpt-4o-mini",
            temperature=0.7,
            max_tokens=400,
        )

        self.rag_service = RAGService()

        # --- INICIO DE LA CORRECCI√ìN DEL PROMPT ---
        self.SYSTEM_PROMPT = """
Eres ‚ÄúAuri‚Äù, un acompa√±ante emocional emp√°tico y c√°lido. Tu prop√≥sito es ser un espacio seguro para que el usuario hable sobre sus *sentimientos*, *emociones*, *preocupaciones* y *pasiones*.

REGLAS IMPORTANTES:
1.  **Mant√©n el Foco**: Tu √∫nico tema de conversaci√≥n es el bienestar emocional del usuario (sus sentimientos, estr√©s, hobbies, etc.).
2.  **NO ERES UN CHATBOT GEN√âRICO**: Eres un diario emp√°tico, NO un motor de b√∫squeda.
3.  **REGLA DE EVASI√ìN (MUY IMPORTANTE)**: Si el usuario te hace una pregunta de conocimiento general, factual, o que no tiene nada que ver con sus sentimientos (ej. "¬øcu√°nto mide la Torre Eiffel?", "¬øc√≥mo salgo de Per√∫?", "¬øqui√©n gan√≥ el partido?"), DEBES redirigir amablemente la conversaci√≥n hacia √©l.

    * Ejemplo de Evasi√≥n 1: "¬°Esa es una pregunta interesante! üòÖ Pero prefiero seguir hablando de ti. ¬øC√≥mo te sientes ahora mismo?"
    * Ejemplo de Evasi√≥n 2: "Mmm, no estoy segura de ese dato. Lo que s√≠ s√© es que estoy aqu√≠ para escucharte. ¬øHay algo m√°s en tu mente?"
    * Ejemplo de Evasi√≥n 3: "Jeje, creo que en eso no te puedo ayudar. Mejor cu√©ntame, ¬øc√≥mo ha estado tu d√≠a? ‚ú®"

4.  **Usa el Contexto**: Si la consulta del usuario S√ç es sobre bienestar (ej. "dame un consejo para el estr√©s"), usa la "Informaci√≥n para Auri" para dar una respuesta informada.
5.  **Tono**: S√© breve, c√°lida y comprensiva. Usa emojis üíú‚ú®üßò‚Äç‚ôÄÔ∏èüìì con moderaci√≥n.
6.  **Angustia Severa**: Si detectas angustia severa, usa la informaci√≥n del RAG para sugerir ayuda profesional (ej. L√≠nea 113).
"""
        # --- FIN DE LA CORRECCI√ìN DEL PROMPT ---

    # ---------------------------------------------------------
    # NORMALIZACI√ìN DEL HISTORIAL
    # ---------------------------------------------------------
    def _convert_history(self, historial_db):
        """
        Convierte historial de BD en mensajes v√°lidos de LangChain.
        Garantiza que no existan mensajes vac√≠os, duplicados o con
        formato incompatible.
        """
        mensajes = []
        ultimo_contenido = None

        for mensaje in historial_db:
            rol = mensaje.get("rol", "").strip()
            texto = mensaje.get("texto", "")

            if not texto or texto.strip() == "":
                continue

            if texto == ultimo_contenido:
                continue

            ultimo_contenido = texto

            if rol == "user":
                mensajes.append(HumanMessage(content=texto))
            else:
                # --- CORRECCI√ìN DE BUG: Usar AIMessage para la IA ---
                mensajes.append(AIMessage(content=texto))

        return mensajes

    # ---------------------------------------------------------
    # FUNCI√ìN PRINCIPAL: INVOCAR AL AGENTE
    # ---------------------------------------------------------
    def invoke(self, texto_usuario: str, datos_usuario: dict, historial_chat_db=None):
        """
        Recibe un mensaje, agrega contexto, historial y genera respuesta.
        """

        print("[ConversationalAgent] Invocando agente...")

        if not texto_usuario or texto_usuario.strip() == "":
            texto_usuario = "(mensaje corto o poco claro)"

        # 1. Extraer nombre
        nombre = datos_usuario.get("nombre", "Usuario")

        # 2. Obtener contexto del RAG
        contexto_kb = self.rag_service.buscar_contexto(texto_usuario)

        # 3. Construir context prompt
        context_prompt = SystemMessage(content=f"""
Informaci√≥n para Auri (NO lo menciones textualmente en la respuesta):

- Nombre del usuario: {nombre}
- Contexto relevante: {contexto_kb or 'No se encontr√≥ contexto relevante. Enf√≥cate en la emoci√≥n del usuario.'}

Usa este contexto para hacer la respuesta m√°s emp√°tica,
pero **NO** digas: "seg√∫n el contexto", "en tu historial" ni nada t√©cnico.
""")

        # 4. Historial normalizado
        historial_msgs = self._convert_history(historial_chat_db or [])

        # 5. Construir mensaje del usuario
        user_msg = HumanMessage(content=texto_usuario)

        # 6. Construir la cadena final de mensajes
        mensajes = [
            SystemMessage(content=self.SYSTEM_PROMPT),
            context_prompt,
        ] + historial_msgs + [user_msg]

        print("\n==============================")
        print("[AURI] MENSAJES ENVIADOS AL MODELO:")
        for m in mensajes:
            print(type(m).__name__, "‚Üí", m.content[:160])
        print("==============================\n")

        try:
            respuesta = self.llm.invoke(mensajes).content
            print("[AURI] RESPUESTA DE OPENAI:", respuesta)
        except Exception as e:
            print("‚ùå ERROR AL LLAMAR A OPENAI:", e)
            raise e

        return respuesta